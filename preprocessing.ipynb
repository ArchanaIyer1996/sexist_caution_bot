{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(sentences):\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    \n",
    "    new_sentences=[]\n",
    "    \n",
    "    for sentence in tqdm(sentences):\n",
    "        sentence = [word for word in sentence.lower().split() if word not in stop_words]\n",
    "        sentence = ' '.join(sentence)\n",
    "        new_sentences.append(sentence)\n",
    "    \n",
    "    return new_sentences    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def punc(sentences):\n",
    "    punctuation = dict.fromkeys([i for i in range(sys.maxunicode)\n",
    "                                 if unicodedata.category(chr(i)).startswith('P')])\n",
    "\n",
    "    new_sentences=[]\n",
    "    \n",
    "    for sentence in tqdm(sentences):\n",
    "        sentence = [i.lower() for i in nltk.word_tokenize(sentence.translate(punctuation))]\n",
    "        sentence= ' '.join(sentence)\n",
    "        new_sentences.append(sentence)\n",
    "    \n",
    "    return new_sentences    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    \n",
    "    tokens=[]\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence=nltk.word_tokenize(sentence)\n",
    "        tokens.append(sentence)\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8829/8829 [00:00<00:00, 136963.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Comment', 'Class'], dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 8829/8829 [00:02<00:00, 3983.03it/s]\n",
      "100%|██████████| 8829/8829 [00:00<00:00, 122456.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['fuck', 'dad'], ['really', 'dont', 'understand', 'point', 'seems', 'mixing', 'apples', 'oranges'], ['majority', 'canadians', 'wrong', 'unless', 'youre', 'supportive', 'idea', 'nothing', 'full', 'proof', 'perfect', 'take', 'chances', 'inadvertently', 'kill', 'son', 'daughter', 'thems', 'breaks', 'always', 'regard', 'collateral', 'damage', 'like', 'wartime', 'sorry', 'cheques', 'mail'], ['listen', 'dont', 'wan', 'na', 'get', 'married', 'man', 'women', 'dont', 'would', 'bother', 'gay', 'people', 'got', 'married', 'stay', 'lane', 'let', 'god', 'nice', 'quick', 'judg', 'like', 'thought', 'wasnt', 'suppose', 'judge', 'people'], ['c', 'c', 'b', 'a1n', 'xu', 'd1ng', '11', 'b0', 'ddng', 'bi', 'c3u', 'nh', '2011', 'c', 'n', 'ho', 'kh', 'ng', 'c', 'c', 'ng', 'b0', 'n', 'ng', 'd3i', 'cu', '11', 'a7u', 'chi', 'e5', 'nh', 'e5c', 'c', 'n', 'ho', 'kh', 'ng', 'c', 'c', 'n', 'ng', 'n', 'gi', 'ef', '11', 'a5t', 'df', 'v', '03n', 'giang', 'c', 'a7n', 'th', 'a1', 'c', 'n', 'ho', 'kh', 'ng', 'r', 'd1t', 'cu', 'd9c', '11', 'b0', 'e3c', 'g', 'th', 'ch', 'ng', 'ta', '11', 'bi', 'bft', 'ai', 'c', '69ng', 'u', 'chu', 'd9ng', 'ho', 'b', 'nh', 'nh', 'b0ng', '11', 'khi', 'ho', 'b', 'nh', 'ch', 'c9', 'th', 'adt', 'f1', '11', 'bfn', 'sau', 'chi', 'bfn', 'tranh', 'th', 'kh', 'ng', 'c', 'n', 'con', '11', 'b0', 'ddng', 'n', 'ch', 'cdn', 'kh', 'c', '11', 'u', '11', 'ebng', 'a1', 'th', 'n', 'b0']]\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.read_csv(os.path.join('data', 'insults', 'train.csv'))\n",
    "df_test=pd.read_csv(os.path.join('data', 'insults', 'test.csv'))\n",
    "df_valid=pd.read_csv(os.path.join('data', 'insults', 'valid.csv'))\n",
    "\n",
    "df=[df_train, df_test, df_valid]\n",
    "df=pd.concat(df)\n",
    "print(df.columns)\n",
    "all_comments=df.Comment.values\n",
    "all_labels=df.Class.values\n",
    "comments=[]\n",
    "\n",
    "for comment in tqdm(all_comments):\n",
    "    comment=re.sub(r\"\\\\+[a-z0-9]{1,3}\", ' ', comment)\n",
    "    comment=re.sub(r'\\@\\w+', ' ', comment)\n",
    "    comments.append(comment)\n",
    "\n",
    "comments=punc(comments)\n",
    "comments=remove_stopwords(comments)\n",
    "comments=tokenize(comments)\n",
    "\n",
    "print(comments[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 657]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  10 657]\n"
     ]
    }
   ],
   "source": [
    "max_words = 1000\n",
    "max_len = 50\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(comments)\n",
    "sequences = tok.texts_to_sequences(comments)\n",
    "print(sequences[0])\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "print(sequences_matrix[0])\n",
    "labels = pd.Series(all_labels).str.get_dummies()\n",
    "labels=np.asarray(labels)\n",
    "\n",
    "import pickle\n",
    "with open('tok.pkl', 'wb') as f:\n",
    "    pickle.dump(tok, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, 50, 100)           100000    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "out_layer (Dense)            (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 159,394\n",
      "Trainable params: 159,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def RNN():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,100,input_length=max_len)(inputs)\n",
    "    layer = LSTM(64)(layer)\n",
    "    layer = Dense(256,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(2,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model\n",
    "\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8829/8829 [==============================] - 10s 1ms/step - loss: 0.5693 - acc: 0.7145\n",
      "Epoch 2/10\n",
      "8829/8829 [==============================] - 6s 656us/step - loss: 0.4494 - acc: 0.7999\n",
      "Epoch 3/10\n",
      "8829/8829 [==============================] - 6s 661us/step - loss: 0.4215 - acc: 0.8171\n",
      "Epoch 4/10\n",
      "8829/8829 [==============================] - 6s 690us/step - loss: 0.4038 - acc: 0.8268\n",
      "Epoch 5/10\n",
      "8829/8829 [==============================] - 6s 662us/step - loss: 0.3942 - acc: 0.8340\n",
      "Epoch 6/10\n",
      "8829/8829 [==============================] - 6s 665us/step - loss: 0.3840 - acc: 0.8362\n",
      "Epoch 7/10\n",
      "8829/8829 [==============================] - 6s 686us/step - loss: 0.3755 - acc: 0.8391\n",
      "Epoch 8/10\n",
      "8829/8829 [==============================] - 6s 677us/step - loss: 0.3606 - acc: 0.8480\n",
      "Epoch 9/10\n",
      "8829/8829 [==============================] - 6s 674us/step - loss: 0.3487 - acc: 0.8549\n",
      "Epoch 10/10\n",
      "8829/8829 [==============================] - 6s 670us/step - loss: 0.3389 - acc: 0.8578\n"
     ]
    }
   ],
   "source": [
    "model.fit(sequences_matrix,labels,batch_size=128,epochs=10)\n",
    "model.save('models/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[657]]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0 657]]\n",
      "Not Insult\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "del tok\n",
    "pred_list=['Insult', 'Not Insult']\n",
    "from keras.models import load_model\n",
    "\n",
    "model=load_model('models/model1.h5')\n",
    "with open('tok.pkl', 'rb') as f:\n",
    "    tok = pickle.load(f)\n",
    "\n",
    "text=[['what', 'the', 'dad']]\n",
    "sequences = tok.texts_to_sequences(text)\n",
    "print(sequences)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)\n",
    "print(sequences_matrix)\n",
    "\n",
    "pred=model.predict(sequences_matrix)\n",
    "\n",
    "print(pred_list[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
